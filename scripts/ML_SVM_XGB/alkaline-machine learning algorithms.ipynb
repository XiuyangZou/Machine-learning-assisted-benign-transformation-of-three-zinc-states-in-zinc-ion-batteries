{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib\n",
    "\n",
    "#GPU设置\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "###########fix random seed for reproducability##########\n",
    "seed=1\n",
    "np.random.seed(seed)\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "###########loading data##########\n",
    "csv = \"../../database/database124.csv\"\n",
    "\n",
    "fdata=pd.read_csv(csv, index_col=0)\n",
    "raw_data = fdata.iloc[:, 1:]\n",
    "\n",
    "median_raw_data=raw_data.median()\n",
    "dict_median_raw_data=median_raw_data.to_dict()\n",
    "data=raw_data.fillna(dict_median_raw_data)\n",
    "#print(data)\n",
    "#print(np.std(data,axis=0))\n",
    "###########data standardization##########\n",
    "standardized_data = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
    "raw_param=standardized_data.iloc[:,0:121]\n",
    "raw_power=standardized_data.iloc[:,121]\n",
    "#print(raw_param)\n",
    "print(raw_power)\n",
    "X=raw_param.values.astype(np.float32)\n",
    "y=raw_power.values.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15)\n",
    "###########defining a wrapper function for later call from each machine learning algorithms##########\n",
    "def try_different_method(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    result = model.predict(X_test)\n",
    "    x_prediction_maximum_power_ann=result*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    print(x_prediction_maximum_power_ann)\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    ###########evaluating the regression quality##########\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(rmse_val)\n",
    "    print(corr_ann)\n",
    "    print(y_real_maximum_power)\n",
    "    ###########generating a figure##########\n",
    "    x_y_x=np.arange(0,10000,100)\n",
    "    x_y_y=np.arange(0,10000,100)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_prediction_maximum_power_ann,y_real_maximum_power,color='red',label='Artificial Neural Network')\n",
    "    plt.legend()\n",
    "    ax.plot(x_y_x,x_y_y)\n",
    "    plt.xlabel(u\"Predicted_Time (h)\")\n",
    "    plt.ylabel(u\"Real_Time (h)\")\n",
    "    plt.show()\n",
    "####import machine learning algorithms packages and define the corresponding models####\n",
    "####Support Vector Regressor####\n",
    "from sklearn import svm\n",
    "model_SVR = svm.SVR()\n",
    "\n",
    "####Random Forest####\n",
    "from sklearn import ensemble\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor()\n",
    "\n",
    "####Gaussian Process####\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "model_GaussianProcessRegressor=GaussianProcessRegressor()\n",
    "\n",
    "####XGBoost####\n",
    "import xgboost as xgb\n",
    "model_XGboostRegressor=xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Gaussian Process Regressor####\n",
    "\n",
    "algorithm_name='Gaussian Process Regressor'\n",
    "try_different_method(model_GaussianProcessRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Support Vector Regressor####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'kernel':['rbf','linear','poly'],\n",
    "         'max_iter':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500],\n",
    "         'degree':[2,3,4],\n",
    "         'gamma':['auto'],\n",
    "         'epsilon':[0.001,0.01,0.1,0.3,0.5,0.7,1],\n",
    "         'coef0':[100,200,300,400,500,600,700,800,1000,1100,1200,1300,1400,1500]\n",
    "       }\n",
    "grid = GridSearchCV(model_SVR,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Support Vector Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####Random Forest####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {'n_estimators':[200,400,800],\n",
    "         'max_depth':[5,10,15],\n",
    "         'min_samples_split':[2,4,6,8],\n",
    "         'min_samples_leaf':[2,4,8],\n",
    "         'max_features':['auto','sqrt','log2']\n",
    "\n",
    "       }\n",
    "\n",
    "grid = GridSearchCV(model_RandomForestRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='Random Forest Regressor'\n",
    "try_different_method(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2\n",
    "np.random.seed(seed)\n",
    "####XGboost####\n",
    "###########defining the parameters dictionary##########\n",
    "param = {\n",
    "         'learning_rate':[0.01,0.1,1],\n",
    "   'n_estimators':[100,200,400,1000,2000,4000,8000],\n",
    "    'max_depth':[5,7,9,11],  \n",
    "    'objective':['reg:squarederror'],\n",
    "    'subsample':[0.5,0.6,0.7,0.8,0.9],\n",
    "    'lambda':[0.1],\n",
    "    'alpha':[0.1]\n",
    "       }\n",
    "grid = GridSearchCV(model_XGboostRegressor,param_grid=param,cv=5)\n",
    "grid.fit(X_train,y_train)\n",
    "print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_) \n",
    "best_model=grid.best_estimator_\n",
    "\n",
    "algorithm_name='XGBoost Regressor'\n",
    "try_different_method(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf26",
   "language": "python",
   "name": "tf26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
