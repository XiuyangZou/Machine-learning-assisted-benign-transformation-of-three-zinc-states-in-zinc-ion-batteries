{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "#from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#%matplotlib\n",
    "\n",
    "###########fix random seed for reproducability##########\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "'''\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "gpu_options =tf.GPUOptions(per_process_gpu_memory_fraction=0.8,allow_growth=True) ##每个gpu占用0.8存\n",
    "config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=True)\n",
    "sess=tf.Session(config=config)\n",
    "'''\n",
    "seed=1\n",
    "np.random.seed(seed)\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "###########loading data##########\n",
    "csv = \"../../database/database124.csv\"\n",
    "\n",
    "fdata=pd.read_csv(csv, index_col=0)\n",
    "raw_data = fdata.iloc[:, 1:]\n",
    "\n",
    "median_raw_data=raw_data.median()\n",
    "dict_median_raw_data=median_raw_data.to_dict()\n",
    "data=raw_data.fillna(dict_median_raw_data)\n",
    "#print(data)\n",
    "#print(np.std(data,axis=0))\n",
    "###########data standardization##########\n",
    "standardized_data = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
    "#standardized_data = (data-data.mean(axis=0))/data.std(axis=0)\n",
    "raw_param=standardized_data.iloc[:,0:121]\n",
    "raw_power=standardized_data.iloc[:,121]\n",
    "#print(raw_param)\n",
    "print(raw_power)\n",
    "X=raw_param.values.astype(np.float32)\n",
    "y=raw_power.values.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15)\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-1-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0)) \n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print('ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%1\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close() \n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-2-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print('ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%2\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-3-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%3\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-4-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%4\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-5-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%5\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-6-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%6\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-7-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%7\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-8-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%8\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-9-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%9\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()\n",
    "\n",
    "file = open('../../results/ANN_Opt_layer/alkaline-ANN-10-layer.txt','w')\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "for neurons in range(50,1050,50):\n",
    "    ###########implementing hyperparameters##########\n",
    "    neurons1=neurons\n",
    "    ###########keras ANN model construction##########\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neurons1, input_dim=121, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                bias_initializer='random_normal',activation='relu',kernel_regularizer=keras.regularizers.l2(0.0001))) \n",
    "    model.add(Dropout(0))\n",
    "    model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "    adam=tf.keras.optimizers.Adam(lr=0.002)\n",
    "    model.compile(loss='mse', optimizer=adam) \n",
    "    #print('Training ------------')\n",
    "    ###########train the model with the training set##########\n",
    "    ###########testset has been remove before##########\n",
    "    model.fit(X_train, y_train,verbose=0, epochs=200, batch_size=32,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "    loss= model.evaluate(X_test, y_test)\n",
    "    predict_ann= model.predict(X_test)\n",
    "    train_ann= model.predict(X_train)\n",
    "    ###########result output##########\n",
    "    x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    y_real_maximum_power=y_test*np.std(data,axis=0)[121]+np.mean(data,axis=0)[121]\n",
    "    x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "    x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "    y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "    corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "    rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "    print(neurons,'ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "    layer_str = '%d'%10\n",
    "    neurons_str = '%d'%neurons\n",
    "    corr_ann_str = '%f'%corr_ann\n",
    "    rmse_val_str = '%f'%rmse_val\n",
    "    file.write(layer_str+' '+ neurons_str +' '+ corr_ann_str+' '+ rmse_val_str +'\\n')\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
