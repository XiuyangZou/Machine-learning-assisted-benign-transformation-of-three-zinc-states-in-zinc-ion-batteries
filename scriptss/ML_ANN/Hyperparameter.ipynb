{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            A1        A2        A3        A4       A5       A6  A7        A8  \\\n",
      "0     9.107689  0.256971  0.256971  0.718469  186.210  176.130  70  0.115118   \n",
      "1     9.206296  0.414352  0.414352  0.557704  122.167  112.087  48  0.120884   \n",
      "2     9.206296  0.414352  0.414352  0.557704  122.167  112.087  48  0.120884   \n",
      "3     9.206296  0.414352  0.414352  0.557704  122.167  112.087  48  0.120884   \n",
      "4    12.093131 -3.594722  0.008941  0.853625  250.275  240.195  88  0.206096   \n",
      "..         ...       ...       ...       ...      ...      ...  ..       ...   \n",
      "785   2.240741  1.259520  1.259520  0.579490  230.310  216.198  86 -0.017787   \n",
      "786   2.178241  1.259520  1.259520  0.579490  230.310  216.198  86 -0.018361   \n",
      "787   2.178241  1.259520  1.259520  0.579490  230.310  216.198  86 -0.018361   \n",
      "788   2.178241  1.259520  1.259520  0.579490  230.310  216.198  86 -0.018361   \n",
      "789   2.178241  1.259520  1.259520  0.579490  230.310  216.198  86 -0.018361   \n",
      "\n",
      "           A9       A10  ...  A414  A415  A416  A417  A418  A419  A420  A421  \\\n",
      "0   -0.507966  0.115118  ...     0     0     0     0     0     0     0     0   \n",
      "1   -0.507407  0.120884  ...     0     0     0     0     0     0     0     0   \n",
      "2   -0.507407  0.120884  ...     0     0     0     0     0     0     0     0   \n",
      "3   -0.507407  0.120884  ...     0     0     0     0     0     0     0     0   \n",
      "4   -0.507966  0.206096  ...     0     0     0     0     0     0     0     0   \n",
      "..        ...       ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
      "785 -0.062225  0.017787  ...     1     0     0     0     0     0     1     0   \n",
      "786 -0.062225  0.018361  ...     1     0     0     0     0     0     1     0   \n",
      "787 -0.062225  0.018361  ...     1     0     0     0     0     0     1     0   \n",
      "788 -0.062225  0.018361  ...     1     0     0     0     0     0     1     0   \n",
      "789 -0.062225  0.018361  ...     1     0     0     0     0     0     1     0   \n",
      "\n",
      "     A422  Unnamed: 423  \n",
      "0    1.68         500.0  \n",
      "1    1.56          60.0  \n",
      "2    1.38           NaN  \n",
      "3    1.95           NaN  \n",
      "4    1.04        1900.0  \n",
      "..    ...           ...  \n",
      "785  2.42        1320.0  \n",
      "786  2.61        2425.0  \n",
      "787  2.80        3312.5  \n",
      "788  2.94        3162.5  \n",
      "789  3.10        3600.0  \n",
      "\n",
      "[790 rows x 423 columns]\n",
      "0     -1.078337\n",
      "1     -1.534518\n",
      "2     -0.186710\n",
      "3     -0.186710\n",
      "4      0.373149\n",
      "         ...   \n",
      "785   -0.228181\n",
      "786    0.917456\n",
      "787    1.837594\n",
      "788    1.682077\n",
      "789    2.135666\n",
      "Name: Unnamed: 423, Length: 790, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf26\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10616\\1765181414.py:93: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[42]+np.mean(data,axis=0)[422]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10616\\1765181414.py:94: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_real_maximum_power=y_test*np.std(data,axis=0)[422]+np.mean(data,axis=0)[422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN,R2 0.4907 RMSE 878.4479\n"
     ]
    }
   ],
   "source": [
    "#########import packages##########\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "#from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#%matplotlib\n",
    "###########fix random seed for reproducability##########\n",
    "seed=1\n",
    "np.random.seed(seed)\n",
    "file = open('parameter.txt','w')\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "###########loading data##########\n",
    "csv = \"../../database/database.csv\"\n",
    "\n",
    "#fdata=pd.read_csv(csv, index_col=0)\n",
    "fdata=pd.read_csv(csv, encoding = 'gbk', index_col=0)\n",
    "print(fdata)\n",
    "raw_data = fdata.iloc[:, 0:]\n",
    "\n",
    "median_raw_data=raw_data.median()\n",
    "dict_median_raw_data=median_raw_data.to_dict()\n",
    "data=raw_data.fillna(dict_median_raw_data)\n",
    "#print(data)\n",
    "#print(np.std(data,axis=0))\n",
    "###########data standardization##########\n",
    "standardized_data = (data-np.mean(data,axis=0))/np.std(data,axis=0)\n",
    "#standardized_data = (data-data.mean(axis=0))/data.std(axis=0)\n",
    "raw_param=standardized_data.iloc[:,0:422]\n",
    "raw_power=standardized_data.iloc[:,422]\n",
    "#print(raw_param)\n",
    "print(raw_power)\n",
    "X=raw_param.values.astype(np.float32)\n",
    "y=raw_power.values.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15)\n",
    "###########search neuron network hyperparmeter space##########\n",
    "dropout_list= np.arange(0, 1, 0.1)\n",
    "neurons=240\n",
    "for activation in ['relu','tanh','softsign']:\n",
    "    for regularizer_term in [0.0001,0.0002,0.0005,0.0008,0.001,0.002,0.005,0.0008,0.01,0.02,0.05,0.08,0.1]:\n",
    "        for dropout in dropout_list:\n",
    "            for epochs_number in range(1000,1200):\n",
    "                for batch_size_number in range (20,2000,40):\n",
    "                    for learning_rate_search in [0.001,0.002,0.005,0.01]:\n",
    "                        ###########implementing hyperparameters##########\n",
    "                        neurons1=neurons\n",
    "                        activation1=activation\n",
    "                        regularizer=keras.regularizers.l2(regularizer_term)\n",
    "                        dropout_rate=dropout\n",
    "                        ###########keras ANN model construction##########\n",
    "                        model = Sequential() \n",
    "                        model.add(Dense(neurons1, input_dim=422, kernel_initializer='random_normal',\n",
    "                                        bias_initializer='random_normal',activation=activation1,kernel_regularizer=regularizer)) \n",
    "                        model.add(Dropout(dropout_rate))\n",
    "                        model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                                    bias_initializer='random_normal',activation=activation1,kernel_regularizer=regularizer)) \n",
    "                        model.add(Dropout(dropout_rate)) \n",
    "                        model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                                    bias_initializer='random_normal',activation=activation1,kernel_regularizer=regularizer)) \n",
    "                        model.add(Dropout(dropout_rate))\n",
    "                        model.add(Dense(neurons1, input_dim=neurons1, kernel_initializer='random_normal',\n",
    "                                    bias_initializer='random_normal',activation=activation1,kernel_regularizer=regularizer)) \n",
    "                        model.add(Dropout(dropout_rate)) \n",
    "                        model.add(Dense(1, input_dim=neurons1, activation='linear'))\n",
    "                        adam=tf.keras.optimizers.Adam(lr=learning_rate_search)\n",
    "                        model.compile(loss='mse', optimizer=adam) \n",
    "                        #print('Training ------------')\n",
    "                        ###########train the model with the training set##########\n",
    "                        ###########testset has been remove before##########\n",
    "                        model.fit(X_train, y_train,verbose=0, epochs=epochs_number, batch_size=batch_size_number,validation_split=0.1,callbacks=[TensorBoard(log_dir='mytensorboard')])\n",
    "                        loss= model.evaluate(X_test, y_test)\n",
    "                        predict_ann= model.predict(X_test)\n",
    "                        train_ann= model.predict(X_train)\n",
    "                        ###########result output##########\n",
    "                        x_prediction_maximum_power_ann=predict_ann*np.std(data,axis=0)[42]+np.mean(data,axis=0)[422]\n",
    "                        y_real_maximum_power=y_test*np.std(data,axis=0)[422]+np.mean(data,axis=0)[422]\n",
    "                        x_prediction_maximum_power_ann=x_prediction_maximum_power_ann[:,0]\n",
    "                        x_prediction_maximum_power_ann_series=pd.Series(x_prediction_maximum_power_ann)\n",
    "                        y_real_maximum_power_series=pd.Series(y_real_maximum_power)\n",
    "                        corr_ann = round(x_prediction_maximum_power_ann_series.corr(y_real_maximum_power_series), 4)\n",
    "                        rmse_val= rmse(x_prediction_maximum_power_ann,y_real_maximum_power)\n",
    "                        print('ANN,R2',corr_ann,'RMSE',rmse_val)\n",
    "                        if corr_ann>0.7:\n",
    "                            file.write('ANN,R2'+' '+ 'RMSE'+' '+ '\\n')\n",
    "                            mm1 ='%f'%corr_ann\n",
    "                            mw1 ='%f'%rmse_val\n",
    "                            neurons1 = '%d'%neurons\n",
    "                            regularizer_term1='%f'%regularizer_term\n",
    "                            dropout1='%f'%dropout\n",
    "                            epochs_number1='%f'%epochs_number\n",
    "                            batch_size_number1='%f'%batch_size_number\n",
    "                            file.write('ANN,R2'+' '+ mm1 +' '+ 'RMSE'+' '+ mw1 +' '+neurons1+' '+regularizer_term1+' '+dropout1+' '+ epochs_number1+' '+batch_size_number1+'\\n')\n",
    "                            if corr_ann > max_corr_ann:\n",
    "                                max_corr_ann = corr_ann\n",
    "                                max_rmse_val = rmse_val\n",
    "                                max_y_real_maximum_power = y_real_maximum_power\n",
    "                                max_x_prediction_maximum_power_ann = x_prediction_maximum_power_ann\n",
    "                                max_learning_rate_search = learning_rate_search\n",
    "                                max_neurons = neurons\n",
    "                                max_activation = activation\n",
    "                                max_regularizer_term = regularizer_term\n",
    "                                max_dropout = dropout\n",
    "                                max_epochs_number = epochs_number\n",
    "                                max_batch_size_number = batch_size_number\n",
    "                        if 0.9<corr_ann<1:\n",
    "                            break\n",
    "                        else:\n",
    "                            K.clear_session()\n",
    "                    else:continue\n",
    "                    break\n",
    "                else:continue\n",
    "                break\n",
    "            else:continue\n",
    "            break\n",
    "        else:continue\n",
    "        break\n",
    "    else:continue\n",
    "    break\n",
    "\n",
    "###########print best hyperparameter##########\n",
    "print(learning_rate_search)\n",
    "print(neurons)\n",
    "print(activation)\n",
    "print(regularizer_term)\n",
    "print(dropout)\n",
    "print(epochs_number)\n",
    "print(batch_size_number)\n",
    "print('ANN,R2',corr_ann)\n",
    "print('ANN,RMSE',rmse_val)\n",
    "print(y_real_maximum_power)\n",
    "###########visualization##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
